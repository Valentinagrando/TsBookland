<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>Data Type</title>
    <link href="./style.css" rel='stylesheet' type='text/css'>
  </head>
  <body>
    <div class="header">
      <nav id="top">
        <a href="./lab1.html" class="btn">Home</a> |
        <a href="./about.html" class="btn">About Me</a> |
        <a href="./data.html" class="btn">Data</a>
      </nav>
    </div>
      <div class="main">
      <h1>My Data Type</h1>
    </div>
    <div class="description">
      <div class='csv'>
        <h1>Forestfires.csv</h1>
        <p>
          &nbsp;&nbsp;I chose to analyze the forestfires.csv file because forest fires are a major problem in the current society and can cause unmeasurable damage to biodiversity aside from being extremely dangerous to those who live in the vicinity of its occurrences. Therefore, I thought it would be interesting to learn a little bit more about and analyze some occurrences of it represented in the forestfires.csv file.
        </p>
        <h2>Question 1</h2>
        <p class='1'>
          &nbsp;&nbsp;The first question I chose to investigate for this dataset is ‘What month, in the period stablished by the dataset, had the most occurrences of forest fires? Build a graph that shows the percentage of each month in the total occurrences of fires. I posed this question because I was intrigued to see if there were any prominent months for forest fires on this dataset.<br />&nbsp;&nbsp;To answer the question I build a Python function called most_fires() that creates a dictionary to store the months, runs through the csv file and identifies if the month is already in the dictionary, in which case it counts that occurrence to the respective month, if not, it includes it and creates a count of the occurrences of that month. After that, the function compares all the values for all the months and registers the highest one and prints a sentence stating which one is the month with the most occurrences of forest fires as well as returns the dictionary with the months and total occurrences for my later use of build a graph with that information. The answer to the first question as August and the column in the dataset that helped me answer this question was the ‘month’ column.<br />&nbsp;&nbsp;The graph I created to answer the second part of the question is the Pie Chart below titled “Forest fires per month in relation to total,in %”. It shows the percentage of every month on the total number of forest fires during the period represented on the dataset. Every month section has it’s own color in the chart and it is accompanied by a legend stating the month and its respective percentage in the same color as the section. Some interesting things about my findings is that the occurrences are concentrated mostly in September and August. These months together amount to almost 70% of all the forest fires in the dataset while some other months represent close to 0%, which is interesting since the concentration, if we count the third biggest: July, falls right in the transition from Summer to Fall.
        </p>
        <img src="./media/Lab2/graph1.png" alt="graph representing the percentage of each month on the number of total forest fires in the dataset"/>

      <h2>Question 2</h2>
      <p class='2'>
        &nbsp;&nbsp;The second question I chose to investigate is “Where there more fires when the relative humidity was greater than or less than 50(%)? Build a graph that compares the number of fires that happened in each circumstance.” I posed this question because I wanted to check if common sense was right, and fires are more likely to happen in dryer weather, or if we would be surprised and find out that it was more likely in humid weather.<br />&nbsp;&nbsp;To answer this question I created a Python function called humidity_factor() that reads from the forestfires.csv file, gets all the information into a list, and creates a new dictionary that will store the number of occurrences for each category lt (less than or equal to 50) and gt (greater than 50). After that, the function runs through the information list created from the file and checks the column RH (relative humidity) and checks in which category the occurrence fits based on the number in that column for said occurrence. Wherever it fits, the count of the lt/gt dictionary is incremented by 1. After going through all the fire instances in the file, the function compares the count in the new dictionary for lt and for gt. If lt is grater, the function prints “There were (the difference between lt and gt numbers) more forest fires in days when the relative humidity was less than or equal to 50% than when it was greater than 50%.”. Now, if gt is greater the function prints: “There were (difference between gt and lt numbers) more forest fires in days when the relative humidity was greater than 50% than when it was less than 50%.”. And if lt is equal to gt, the function prints: “There were as many forest fires in days when the relative humidity was less than 50% as in days when it was greater than 50%.”. The answer to my question agrees with common sense, there were more fires when RH was less than or equal to 50. The function also returns the data I would later need to write a csv file for making my graph, that is the lt/gt dictionary.The column on the dataset that I used to aswer the question was the RH (Relative Humidity) column.<br />&nbsp;&nbsp;The graph I created to answer the second part of the question is a Bar Chart titled “Number of forest fires in relation to relative humidity”. It shows the total quantity of forest fires that happened when the relative humidity was less than or equal to 50 and when it was greater than 50. The graph is supposed to compare both quantities and give a visual support to the first answer apart from improving it. Something interesting about my findings is that the difference is very big between the gt bar and the lt bar. 363 vs 154 occurrences. Furthermore, the number for gt is actually very big, 154, having in mind that most people believe that a higher rate of relative humidity would stop a fire from happening. This graph proves that that notion is wrong.

      </p>
      <img src="./media/Lab2/graph2.png" alt="graph representing a comparison between the number of forest fires that happened when the relative humidity was less than or equal to 50 and when it was greater"/>

      <h2>Question 3</h2>
      <p class='3'>
        &nbsp;&nbsp;The third question I chose to investigate is “Were there forest fires that had a burnt area bigger than Georgia Tech’s campus in Atlanta? If yes, how many? Build a graph comparing their area to GT Campus”. I posed this question in order to put some context to the tragedy of forest fires by comparing the area affected to a space known by all GT students.<br />&nbsp;&nbsp;To answer this question I created a Python function called fire_area() that reads from the forestfires.csv file, loops through the list of fires, transforms the info in the column area from ha into acres by multiplying it by 2.47105 in order to compare it to GT’s 400-acre area. After comparing, if the area is indeed bigger, a count that is initialized as 0 in the beginning of the function is incremented by 1 to count the times an area is bigger than GT and that area and the month of the occurrence of that fire are added to a list I’ll further need to build my graph. In the end of the loop, the function prints the answer to the question in the form of:” There were (count number) fires that had a burnt area bigger than Georgia Tech's campus in Atlanta.”. The answer is 8 fires. The column I used to answer this question was the area column Finally, the function returns the list with the month of occurrence of the forest fires that had a bigger area than GT Campus’ and how much bigger it is, compared to GT.<br />&nbsp;&nbsp;The graph I created to answer the second part of the question is a Bar Chart titled “Burnt area (masured in GT Campus units)”. It shows how many times Georgia Tech’s Campus would have fit inside of the burnt area for that forest fire, in other words, how big it was compared to GT Campus, as well as the month said fire occurred. Some interesting things about my findings is that even though Georgia Tech Campus is extremely large, for example, it takes 30 minutes to walk from one end to the other, there was a fire in September that had a burnt area of 6.74 GT Campuses! It would take approximately 3 hours and 22 minutes to walk from one end to the other of that area. Also, my findings for this data would complement my first graph and function since by appearing the most in this graph, the months of August and September, besides having the most fires, mainly August, they also have the most violent ones, with a bigger burnt area.
      </p>
      <img src="./media/Lab2/graph3.png" alt="graph representing a comparison between the burnt area of forest fires that was bigger than GT campus and GT Campus itself."/>
      </div>
      <div class='json'>
        <h1>Facebook.json</h1>
        <p>
          &nbsp;&nbsp;I chose to analyze facebook.json because it represents a more in depth look into a page of a social media I use daily and being able to have an analytical look towards it, especially when using my own coding skills in order to analyze it, seemed very interesting. Therefore, I thought it would be the most exciting file to use.
        </p>
        <h2>Question 1</h2>
        <p class='1'>
          &nbsp;&nbsp;The first question I decided to investigate for this dataset is “Which post type had the greatest average reach per post? Design a graph that compares the reach each post type for the entire dataset.” I posed this question because I have always been curious about whether the type of content you posted ended up reaching more of your friends on Facebook, so I decided to use this opportunity to discover it.<br />&nbsp;&nbsp;To answer this question I created a Python function called reach() that opens the json file, transforms into a Python dictionary object, loops through that object, counts every time a post of a certain type is looped through, there are 4 counts, one for each type (Photo,Video,Status,Link),  creates a new dictionary that has a key for each type and for each loop, adds the number of “Lifetime Post total Reach” for that post on the current loop to its respective type total on the dictionary.  It then divides each type’s total reach in the dictionary by the number of posts of that type (its respective count) to get the average reach by post. Then, the function goes through those averages and identifies the highest and prints a string on this format: “The post type that can reach the clients in Facebook the most per post is (post type).”. The answer to my question is Video and the information that helped me determine that were "Type" and "Lifetime Post Total Reach". Finally, the function returns the dictionary with all the 4 averages for me to be able to use that information later on to build my graph.<br />&nbsp;&nbsp;The graph I created to answer the second part of my question is a Bar Chart titled “Average users reached per post (for each Type) for the sample”. It shows the average number of users reached by that post type per post in comparison to the other types’ averages. I decided not to round the numbers to the nearest integer even though we are talking about people, because this way we have a better understanding that some posts will have more reach than that and some will have less, it is not a set number, and this paints that image better. One interesting thing about my findings is that since Instagram is very famous, we expect photos to be the post type to have the largest reach, but no, Video is the one that was the greatest reach out of the four types.
        </p>
        <img src="./media/Lab2/graph4.png" alt="graph representing the average number of users that follow the page reached per post, divided into type of post"/>

        <h2>Question 2</h2>
        <p class='2'>
          &nbsp;&nbsp;The second question I chose to investigate for this dataset is “Do the posts get more average likes per post during the week or during the weekend? How much more? Build a graph that shows the average number of likes per post on a post made on each of the days of the week”. I posed this question because again I wanted to challenge common sense, which dictates that people use Facebook more on the weekends and therefore posts on these days had to have more likes per post. I wanted to see if this assumption really holds true in this dataset.<br />&nbsp;&nbsp;To answer the first part of my question I made a Python function called likes_days() that opens the json file, transforms it into a Python dictionary object, creates a new dictionary (newdict) to store the likes in posts of each day of the week, a list (days) that relates the numbers in the file that represent days of the week to actual words that represent the days by using those numbers to form the index of those words in the list, as well as a countdict dictionary that keeps count of how many posts were made total in each of the days of the week during the loop. After having newdict with the total likes for all the posts for each day of the week, and a countdict with the total posts made on each day, the function organizes the newdict so that it is in the right order (Sunday to Saturday) and then divides the total likes on each day by the total number of posts for that day to create an average of likes per post. After that it compares the averages from Monday to Friday to the one for Saturday and Sunday. If weekdays average is bigger it prints: “The posts get more likes over the week than in the weekend. More specifically (the difference between averages) more average likes per post in the total of the sample.”. If weekend average is bigger, it prints: “The posts get more likes over the weekend than during the week. More specifically (the difference between averages) more average likes per post in the total of the sample.”. If the averages are equal, it prints: “The posts get the same number of average likes per post over the week as they do in the weekend.”. The answer to the question is: posts get more likes over the week than in the weekend. More specifically 39885 more average likes per post in the total of the sample and the information that helped me determine that was ‘like’ and ‘Post Weekday’. Finally, the function returns the newdict with the averages for each day of the week for my further use in building the graph.<br />&nbsp;&nbsp;The graph I created to answer the second part of the question is a Bar Chart titled “Average number of likes on a post made in a given day of the week”. It shows the average number of likes per post made on that specific day of the week and puts it in a comparative way with the other days’ averages. Some interesting things about my findings is that the data contradicts common sense, confirming that in this case, the post actually gets more likes over the week, which would be logical considering there are more days during the week than in the weekend. But it goes beyond that. The day that actually has the greatest average likes per post in this case is, shockingly, Tuesday.

        </p>
        <img src="./media/Lab2/graph5.png" alt="graph representing a comparison between the number of average likes per post for posts posted on each of the days of the week "/>

        <h2>Question 3</h2>
        <p class='3'>
          &nbsp;&nbsp;The third question I decided to investigate for this dataset is “When does a post get a greater average per post of engaged users? When it is posted in hours between 0-12 or between 13-23? Build a graph that represents the different time periods’ posts percentage of total engaged users for the page on the dataset. What percentage of the total engaged users is represented by the number of engaged users on those time periods?”. I posed this question because I have always been an night owl, but I never knew if most of the social media community was too, so I decided to test that with this dataset and this question.<br />&nbsp;&nbsp;To answer the first part of my question I created a Python function that opens the json file, transforms it into a Python dictionary object, creates a new dictionary (newdict) that will keep count of the number of engaged users for both periods of time (0hrs-12hrs and 13hrs-23hrs), a count 1 and 2 to keep count of the amount of posts made in those periods, as well as a dictaverage, which will store later in the average of engaged uses per post on those time periods. After that the function loops through the Python object checking the hours each post was made and each on each post it adds the number of engaged users for that post on newdict in the right post time period as well as adds 1 to the its respective count to keep track of the number of posts. Then, the function adds to the dict average the average of engaged users per post by divinding the total number of engaged users on each time frame by their respective count. Finally, compares the averages and if the 0-12 average is bigger, it prints: “A post has more engaged users per post between midnight and 12pm”. If the 13-23 average is bigger, it prints: “A post has more engaged users per post between 12pm and 11pm”. If they are equal it prints: “Time of postage does not affect the number of engaged users per post”. As a final step, newdict is returned in the function for my further use in building the graph mentioned above.<br />&nbsp;&nbsp;The graph I created to answer the second part of the question is a Pie Chart titled “Percentage of total engaged Facebook users (for that page) on posts between 12am-12pm and 1pm -11pm”. It shows what percentage of the total number of engaged users on that page is represented in the number of engaged users for posts between midnight and 12pm and between 1pm and 11pm. An interesting thing about my findings are that the results show that most of engaged users for that page are also night owls since 83% of total engaged users are engaged users in posts between midnight and 12pm, but that also seems to be because the number of posts at that time is bigger. So while the number of engaged users per post is bigger for 1pm to 11pm, because the number of posts made between midnight and 12pm is bigger, the number of total engaged users is bigger.
        </p>
        <img src="./media/Lab2/graph6.png" alt="graph representing the what percentage of the total number of engaged users on that page is represented in the number of engaged users for posts between midnight and 12pm and between 1pm and 11pm"/>

      </div>
    </div>
    <div class="footer">
      <div class="author">
        <p>
          @ 2018 Valentina B. Grando
        </p>
      </div>
      <div class="upbutton">
        <a href="#top" class="btn">Back to the top</a>
      </div>
      <div class="footerlinks">
        <a href="https://linkedin.com/in/valentina-b-grando/" target="_blank" class="btn">LinkedIn</a>  <a href="https://www.goodreads.com/user/show/18986704-val-grando" target="_blank" class="btn">Goodreads</a>
      </div>
    </div>
  </body>
</html>
